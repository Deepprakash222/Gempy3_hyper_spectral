{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all the libraries and packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import MCMC, NUTS, Predictive, EmpiricalMarginal\n",
    "from pyro.infer.autoguide import init_to_mean, init_to_median, init_to_value\n",
    "from pyro.infer.inspect import get_dependencies\n",
    "from pyro.infer import SVI, TraceEnum_ELBO, config_enumerate, infer_discrete\n",
    "\n",
    "import gempy as gp\n",
    "import gempy_engine\n",
    "import gempy_viewer as gpv\n",
    "from gempy_engine.core.backend_tensor import BackendTensor\n",
    "import arviz as az\n",
    "from gempy_probability.plot_posterior import default_red, default_blue, PlotPosterior\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import multivariate_normal, norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the path of all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_a = './Fw__Hyperspectral_datasets_from_the_KSL_cores/CuSp131.pkl'\n",
    "filename_b = './Fw__Hyperspectral_datasets_from_the_KSL_cores/CuSp133.pkl'\n",
    "filename_c = './Fw__Hyperspectral_datasets_from_the_KSL_cores/CuSp136.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename_a, 'rb') as myfile:\n",
    "    a= joblib.load(myfile)\n",
    "a.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description about Hyperspectral data\n",
    "## Data is obtained by scannig the core data from different boreholes using hyperspectral sensors. There were around 450 channels for each pixels initially. It was preprocessed and seperated based on 10 different types of rocks. In each of the file we have \"X\", \"Y\", \"Z\" coordinates points corresponding to sensors and corresponding to each rock type we have a transformed RGB correspondence information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name =[]\n",
    "for keys, _ in a.items():\n",
    "    if keys=='XYZ':\n",
    "        column_name.append(\"Borehole_id\")\n",
    "        column_name.append(\"X\")\n",
    "        column_name.append(\"Y\")\n",
    "        column_name.append(\"Z\")\n",
    "    else:\n",
    "        column_name.append(keys+\"_R\")\n",
    "        column_name.append(keys+\"_G\")\n",
    "        column_name.append(keys+\"_B\")\n",
    "data_a =[]\n",
    "for keys, values in a.items():\n",
    "    if keys=='XYZ':\n",
    "        label_a = np.ones((235,1))\n",
    "        data_a.append(label_a)\n",
    "        data_a.append(values)\n",
    "    else:\n",
    "        data_a.append(values/255)\n",
    "\n",
    "# Concatenate the arrays horizontally to create an array of size 5x30\n",
    "concatenated_array_a = np.hstack(data_a)\n",
    "# sort the data based on the depth\n",
    "sorted_indices = np.argsort(-concatenated_array_a[:, 3])\n",
    "concatenated_array_a = concatenated_array_a[sorted_indices]\n",
    "concatenated_array_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataframe_KSL = pd.DataFrame(concatenated_array_a,columns=column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_KSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_data = dataframe_KSL.iloc[:,4:]\n",
    "spectral_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 10, figsize=(20,10))\n",
    "for i in range(10):\n",
    "    colum_start = 3 *i\n",
    "    colum_end = 3 *i +3\n",
    " \n",
    "    ax[i].imshow(spectral_data.iloc[:,colum_start:colum_end]) \n",
    "    \n",
    "# Remove axis labels for clarity\n",
    "for ax in ax:\n",
    "    ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list =['BR_Anhydrite_R',\n",
    " 'BR_Anhydrite_G',\n",
    " 'BR_Anhydrite_B',\n",
    " 'BR_Qtz_Fsp_Cal_R',\n",
    " 'BR_Qtz_Fsp_Cal_G',\n",
    " 'BR_Qtz_Fsp_Cal_B'\n",
    " ]\n",
    "hsi_data = dataframe_KSL[column_list]\n",
    "hsi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Since it is difficult to classify a hyperspectral data in general. We can apply different classical clustering methods to have some starting guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#gm = KMeans(n_clusters=3, random_state=42).fit(X)\n",
    "#gm = GaussianMixture(n_components=3, random_state=0).fit(X)\n",
    "gm = BayesianGaussianMixture(n_components=3,covariance_type='full', random_state=0).fit(hsi_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.means_ , gm.covariances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_mean = torch.tensor(gm.means_)\n",
    "loc_cov  = torch.tensor(gm.covariances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gmm_label = gm.predict(hsi_data)\n",
    "print(y_gmm_label)\n",
    "\n",
    "y_gmm_label_arranged = torch.Tensor(y_gmm_label+1)\n",
    "y_gmm_label_arranged "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We use the normalised hsi data y_obs_label information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_obs_label = hsi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model_test = gp.create_geomodel(\n",
    "    project_name='Gempy_abc_Test',\n",
    "    extent=[0, 1000, -500, 500, -900, -700],\n",
    "    resolution=[100,100,100],\n",
    "    refinement=3,\n",
    "    structural_frame= gp.data.StructuralFrame.initialize_default_structure()\n",
    "    )\n",
    "p2d = gpv.plot_2d(geo_model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model_test.grid.active_grids_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.add_surface_points(\n",
    "    geo_model=geo_model_test,\n",
    "    x=[100.0, 900.0],\n",
    "    y=[0.0, 0.0],\n",
    "    z=[brk1, brk1],\n",
    "    elements_names=['surface1', 'surface1']\n",
    ")\n",
    "gpv.plot_2d(geo_model_test, cell_number=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.add_orientations(\n",
    "    geo_model=geo_model_test,\n",
    "    x=[500],\n",
    "    y=[0.0],\n",
    "    z=[brk1],\n",
    "    elements_names=['surface1'],\n",
    "    pole_vector=[[0, 0, 1]]\n",
    ")\n",
    "\n",
    "gpv.plot_2d(geo_model_test, cell_number=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model_test.update_transform(gp.data.GlobalAnisotropy.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.compute_model(geo_model_test, engine_config=gp.data.GemPyEngineConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model_test.interpolation_options.kernel_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpv.plot_2d(geo_model_test, cell_number=[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpv.plot_3d(geo_model_test, show_surfaces=True, image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model_test.structural_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brk2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element2 = gp.data.StructuralElement(\n",
    "    name='surface2',\n",
    "    color=next(geo_model_test.structural_frame.color_generator),\n",
    "    surface_points=gp.data.SurfacePointsTable.from_arrays(\n",
    "        x=np.array([100.0, 900.0]),\n",
    "        y=np.array([0.0, 0.0]),\n",
    "        z=np.array([brk2, brk2]),\n",
    "        names='surface2'\n",
    "    ),\n",
    "    orientations=gp.data.OrientationsTable.initialize_empty()\n",
    ")\n",
    "\n",
    "geo_model_test.structural_frame.structural_groups[0].append_element(element2)\n",
    "# Compute and visualize the updated model:\n",
    "gp.compute_model(geo_model_test)\n",
    "gpv.plot_2d(geo_model_test, cell_number=5, legend='force')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpv.plot_3d(geo_model_test, image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model_test.structural_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model_test.structural_frame.structural_groups[0].elements[0], geo_model_test.structural_frame.structural_groups[0].elements[1] = \\\n",
    "geo_model_test.structural_frame.structural_groups[0].elements[1], geo_model_test.structural_frame.structural_groups[0].elements[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model_test.structural_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpv.plot_2d(geo_model_test, cell_number=5, legend='force')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a custome grid where the observed data information is available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_loc = 300\n",
    "y_loc = 0\n",
    "z_loc = dataframe_KSL['Z']\n",
    "xyz_coord = np.array([[x_loc, y_loc, z] for z in z_loc])\n",
    "gp.set_custom_grid(geo_model_test.grid, xyz_coord=xyz_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_coords_copy_test = geo_model_test.interpolation_input.surface_points.sp_coords.copy()\n",
    "geo_model_test.transform.apply_inverse(sp_coords_copy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.add_surface_points(\n",
    "    geo_model=geo_model_test,\n",
    "    x=[x_loc, x_loc],\n",
    "    y=[0.0, 0.0],\n",
    "    z=[brk1, brk2],\n",
    "    elements_names=['surface1', 'surface2']\n",
    ")\n",
    "gpv.plot_2d(geo_model_test, cell_number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model_test.surface_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.compute_model(geo_model_test)\n",
    "gpv.plot_2d(geo_model_test, cell_number=5, legend='force')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_coords_copy_test = geo_model_test.interpolation_input.surface_points.sp_coords.copy()\n",
    "geo_model_test.transform.apply_inverse(sp_coords_copy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the backend to PyTorch for probabilistic modeling\n",
    "BackendTensor.change_backend_gempy(engine_backend=gp.data.AvailableBackends.PYTORCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model_test.interpolation_options.uni_degree = 0\n",
    "geo_model_test.interpolation_options.mesh_extraction = False\n",
    "geo_model_test.interpolation_options.sigmoid_slope = 1100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geo_model_test.solutions.octrees_output[0].last_output_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_grid_values = geo_model_test.solutions.octrees_output[0].last_output_center.custom_grid_values\n",
    "custom_grid_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_obs_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model_test.surface_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model_test.orientations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model_test.transform.apply_inverse(sp_coords_copy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_obs_label = torch.tensor(y_obs_label.to_numpy(),dtype=torch.float64)\n",
    "y_obs_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "@config_enumerate\n",
    "def model_test(y_obs_label):\n",
    "    \"\"\"\n",
    "    This Pyro model represents the probabilistic aspects of the geological model.\n",
    "    It defines a prior distribution for the top layer's location and\n",
    "    computes the thickness of the geological layer as an observed variable.\n",
    "    \"\"\"\n",
    "    # Define prior for the top layer's location\n",
    "    prior_mean_surface_1 = sp_coords_copy_test[2, 2]\n",
    "    prior_mean_surface_2 = sp_coords_copy_test[5, 2]\n",
    "    \n",
    "    \n",
    "\n",
    "    mu_surface_1 = pyro.sample('mu_1', dist.Normal(prior_mean_surface_1, torch.tensor(0.02, dtype=torch.float64)))\n",
    "    mu_surface_2 = pyro.sample('mu_2', dist.Normal(prior_mean_surface_2, torch.tensor(0.02, dtype=torch.float64)))    \n",
    "    \n",
    "    \n",
    "    # Ensure that mu_surface_1 is greater than mu_surface_2\n",
    "    pyro.sample('mu_1 > mu_2', dist.Delta(torch.tensor(1.0, dtype=torch.float64)), obs=(mu_surface_1 > mu_surface_2))\n",
    "    # Update the model with the new top layer's location\n",
    "    interpolation_input = geo_model_test.interpolation_input\n",
    "    \n",
    "    \n",
    "    interpolation_input.surface_points.sp_coords = torch.index_put(\n",
    "        interpolation_input.surface_points.sp_coords,\n",
    "        (torch.tensor([2]), torch.tensor([2])),\n",
    "        mu_surface_1\n",
    "    )\n",
    "    interpolation_input.surface_points.sp_coords = torch.index_put(\n",
    "        interpolation_input.surface_points.sp_coords,\n",
    "        (torch.tensor([5]), torch.tensor([2])),\n",
    "        mu_surface_2\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # # Compute the geological model\n",
    "    geo_model_test.solutions = gempy_engine.compute_model(\n",
    "        interpolation_input=interpolation_input,\n",
    "        options=geo_model_test.interpolation_options,\n",
    "        data_descriptor=geo_model_test.input_data_descriptor,\n",
    "        geophysics_input=geo_model_test.geophysics_input,\n",
    "    )\n",
    "    \n",
    "    # Compute and observe the thickness of the geological layer\n",
    "    \n",
    "    custom_grid_values = geo_model_test.solutions.octrees_output[0].last_output_center.custom_grid_values\n",
    "    \n",
    "    lambda_ = 20\n",
    "    # #class_label = F.softmax(-lambda_* (torch.tensor([1,2,3], dtype=torch.float64) - custom_grid_values.reshape(-1,1))**2, dim=1)\n",
    "    z_nk = F.softmax(-lambda_* (torch.tensor([1,2,3], dtype=torch.float64) - custom_grid_values.reshape(-1,1))**2, dim=1)\n",
    "    # #class_label = torch.mean(F.softmax(-lambda_* (torch.tensor([1,2,3,4,5,6], dtype=torch.float64) - custom_grid_values.reshape(-1,1))**2, dim=1),dim=0)\n",
    "    \n",
    "    N_k = torch.sum(z_nk,axis=0)\n",
    "    N = len(custom_grid_values)\n",
    "    pi_k = N_k /N\n",
    "    #print(pi_k)\n",
    "    mean = []\n",
    "    cov = []\n",
    "    for i in range(z_nk.shape[1]):\n",
    "        mean_k = torch.sum( z_nk[:,i][:,None] * y_obs_label, axis=0)/ N_k[i]\n",
    "        #cov_k = torch.sum( (normalised_hsi - mean_k.reshape((-1,1))) (normalised_hsi - mean_k).T )\n",
    "        cov_k = torch.zeros((mean_k.shape[0],mean_k.shape[0]),dtype=torch.float64)\n",
    "        for j in range(z_nk.shape[0]):\n",
    "                cov_k +=  z_nk[j,i]* torch.matmul((y_obs_label[j,:] - mean_k).reshape((-1,1)) ,(y_obs_label[j,:] - mean_k).reshape((1,-1)))\n",
    "        mean.append(mean_k)\n",
    "        cov_k=cov_k/N_k[i] + 1e-5 * torch.diag(torch.ones(cov_k.shape[0],dtype=torch.float64))\n",
    "        cov.append(cov_k)\n",
    "    mean_tensor = torch.stack(mean, dim=0)\n",
    "    cov_tensor = torch.stack(cov,dim=0)\n",
    "    \n",
    "    \n",
    "    with pyro.plate('N='+str(y_obs_label.shape[0]), y_obs_label.shape[0]):\n",
    "        assignment = pyro.sample(\"assignment\", dist.Categorical(pi_k))\n",
    "        \n",
    "        obs = pyro.sample(\"obs\", dist.MultivariateNormal(loc=mean_tensor[assignment],covariance_matrix=cov_tensor[assignment]), obs=y_obs_label)\n",
    "        \n",
    "    return obs\n",
    "dependencies = get_dependencies(model_test, model_args=(y_obs_label,))\n",
    "pyro.render_model(model_test, model_args=(y_obs_label,),render_distributions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( y_obs_label.shape)\n",
    "model_test(y_obs_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = Predictive(model_test, num_samples=100)(y_obs_label)\n",
    "\n",
    "# Key to avoid\n",
    "avoid_key = 'mu_1 > mu_2'\n",
    "\n",
    "# Create sub-dictionary without the avoid_key\n",
    "prior = dict((key, value) for key, value in prior.items() if key != avoid_key)\n",
    "\n",
    "data = az.from_pyro(prior=prior)\n",
    "az.plot_trace(data.prior)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.primitives.enable_validation(is_validate=True)\n",
    "nuts_kernel = NUTS(model_test, step_size=0.0085, adapt_step_size=True, target_accept_prob=0.9, max_tree_depth=10, init_strategy=init_to_mean)\n",
    "#nuts_kernel = NUTS(model_test, step_size=0.00085, adapt_step_size=True, target_accept_prob=0.9, max_tree_depth=10)\n",
    "#nuts_kernel = NUTS(model_test)\n",
    "initial_values = {'mu_1': torch.tensor(0.01, dtype=torch.float64),'mu_2': torch.tensor(0.01, dtype=torch.float64) }\n",
    "#mcmc = MCMC(nuts_kernel, num_samples=200, warmup_steps=50, disable_validation=False, initial_params=initial_values)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=200, warmup_steps=50, disable_validation=False)\n",
    "mcmc.run(y_obs_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = mcmc.get_samples()\n",
    "posterior_predictive = Predictive(model_test, posterior_samples)(y_obs_label)\n",
    "data = az.from_pyro(posterior=mcmc, prior=prior, posterior_predictive=posterior_predictive)\n",
    "az.plot_trace(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_mean_posterior, loc_cov_posterior =[], []\n",
    "for key, values in posterior_samples.items():\n",
    "    print(key)\n",
    "    if key == \"sample_data\":\n",
    "        mean = values.mean(dim=0)\n",
    "        cov = values.std(dim=0)\n",
    "        print(\"mean\\n\",mean)\n",
    "        print(\"cov\\n\", cov)\n",
    "        loc_mean_posterior.append(mean.detach().numpy())\n",
    "        loc_cov_posterior.append(cov.detach().numpy())\n",
    "    elif key == \"sigma_data\":\n",
    "        print(\"mean\\n\",values.mean(dim=0), \"\\nstd\\n\", values.std(dim=0))\n",
    "    else:\n",
    "        print(\"mean\\n\",values.mean(), \"\\nstd\\n\", values.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_mean_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_cov_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "x = np.linspace(-0.5,1.5,8000)\n",
    "  # Combine x and y grids into a (100, 100, 2) array\n",
    "for i in range(3):\n",
    "    # Create a multivariate normal distribution\n",
    "    rv = norm(loc_mean_posterior[0][i], loc_cov_posterior[0][i])\n",
    "\n",
    "    # Calculate PDF values for each point in the grid\n",
    "    pdf_values = rv.pdf(x)\n",
    "\n",
    "    # Plot the Gaussian distribution using contour plot\n",
    "    \n",
    "    plt.scatter(x, pdf_values, s=2.5, label='Gaussian_'+str(i+1))\n",
    "#plt.colorbar(label='Probability Density')\n",
    "plt.xlabel('hsi_spectra')\n",
    "plt.ylabel('Unnormalized Probability Density')\n",
    "plt.title('Gaussian Distribution')\n",
    "#plt.scatter(loc_mean[i], color='red', label='Mean')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_density(\n",
    "    data=[data.posterior, data.prior],\n",
    "    shade=.9,\n",
    "    var_names=['mu_1'],\n",
    "    data_labels=[\"Posterior Predictive\", \"Prior Predictive\"],\n",
    "    colors=[default_red, default_blue],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_density(\n",
    "    data=[data.posterior, data.prior],\n",
    "    shade=.9,\n",
    "    var_names=['mu_2'],\n",
    "    data_labels=[\"Posterior Predictive\", \"Prior Predictive\"],\n",
    "    colors=[default_red, default_blue],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the model with the new top layer's location\n",
    "interpolation_input = geo_model_test.interpolation_input\n",
    "interpolation_input.surface_points.sp_coords = torch.index_put(\n",
    "    interpolation_input.surface_points.sp_coords,\n",
    "    (torch.tensor([2]), torch.tensor([2])),\n",
    "    posterior_samples[\"mu_1\"].mean()\n",
    ")\n",
    "interpolation_input.surface_points.sp_coords = torch.index_put(\n",
    "    interpolation_input.surface_points.sp_coords,\n",
    "    (torch.tensor([5]), torch.tensor([2])),\n",
    "    posterior_samples[\"mu_2\"].mean()\n",
    ")\n",
    "\n",
    "#print(\"interpolation_input\",interpolation_input.surface_points.sp_coords)\n",
    "\n",
    "# # Compute the geological model\n",
    "geo_model_test.solutions = gempy_engine.compute_model(\n",
    "    interpolation_input=interpolation_input,\n",
    "    options=geo_model_test.interpolation_options,\n",
    "    data_descriptor=geo_model_test.input_data_descriptor,\n",
    "    geophysics_input=geo_model_test.geophysics_input,\n",
    ")\n",
    "\n",
    "gpv.plot_2d(geo_model_test, cell_number=5, legend='force')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_coords_copy_test2 =interpolation_input.surface_points.sp_coords\n",
    "sp_coords_copy_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_cord= geo_model_test.transform.apply_inverse(sp_coords_copy_test2.detach().numpy())\n",
    "sp_cord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model_post = gp.create_geomodel(\n",
    "    project_name='Gempy_post_Test',\n",
    "    extent=[0, 1000, -10, 10, -900, -400],\n",
    "    resolution=[100,10,100],\n",
    "    refinement=7,\n",
    "    structural_frame= gp.data.StructuralFrame.initialize_default_structure()\n",
    "    )\n",
    "gp.add_surface_points(\n",
    "    geo_model=geo_model_post,\n",
    "    x=sp_cord[3:,0],\n",
    "    y=sp_cord[3:,1],\n",
    "    z=sp_cord[3:,2],\n",
    "    elements_names=['surface1', 'surface1','surface1']\n",
    ")\n",
    "gp.add_orientations(\n",
    "    geo_model=geo_model_post,\n",
    "    x=[500],\n",
    "    y=[0.0],\n",
    "    z=[brk1],\n",
    "    elements_names=['surface1'],\n",
    "    pole_vector=[[0, 0, 1.0]]\n",
    ")\n",
    "gpv.plot_2d(geo_model_post, cell_number=5, legend='force')\n",
    "geo_model_test.update_transform(gp.data.GlobalAnisotropy.NONE)  \n",
    "gp.compute_model(geo_model_post, engine_config=gp.data.GemPyEngineConfig())\n",
    "gpv.plot_2d(geo_model_post, cell_number=[5])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element2 = gp.data.StructuralElement(\n",
    "    name='surface2',\n",
    "    color=next(geo_model_post.structural_frame.color_generator),\n",
    "    surface_points=gp.data.SurfacePointsTable.from_arrays(\n",
    "        x=sp_cord[:3,0],\n",
    "        y=sp_cord[:3,1],\n",
    "        z=sp_cord[:3,2],\n",
    "        names='surface2'\n",
    "    ),\n",
    "    orientations=gp.data.OrientationsTable.initialize_empty()\n",
    ")\n",
    "geo_model_post.structural_frame.structural_groups[0].append_element(element2)\n",
    "gp.compute_model(geo_model_post)\n",
    "#gpv.plot_2d(geo_model_post, cell_number=5, legend='force')\n",
    "geo_model_post.structural_frame.structural_groups[0].elements[0], geo_model_post.structural_frame.structural_groups[0].elements[1] = \\\n",
    "geo_model_post.structural_frame.structural_groups[0].elements[1], geo_model_post.structural_frame.structural_groups[0].elements[0]\n",
    "gpv.plot_2d(geo_model_post, cell_number=5, legend='force')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model_post.surface_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating marginal distribution plots\n",
    "# p = PlotPosterior(data)\n",
    "# p.create_figure(figsize=(9, 5), joyplot=False, marginal=True, likelihood=False)\n",
    "# p.plot_marginal(\n",
    "#     var_names=['mu_1', 'mu_2'],\n",
    "#     plot_trace=False,\n",
    "#     credible_interval=.70,\n",
    "#     kind='kde',\n",
    "#     marginal_kwargs={\"bw\": 1}\n",
    "# )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualizing the posterior distributions\n",
    "# p = PlotPosterior(data)\n",
    "# p.create_figure(figsize=(9, 6), joyplot=True)\n",
    "# iteration = 99\n",
    "# p.plot_posterior(\n",
    "#     prior_var=['mu_1', 'mu_2'],\n",
    "#     like_var=['mu_1', 'mu_2'],\n",
    "#     obs='obs',\n",
    "#     iteration=iteration,\n",
    "#     marginal_kwargs={\n",
    "#         \"credible_interval\": 0.94,\n",
    "#         'marginal_kwargs': {\"bw\": 1},\n",
    "#         'joint_kwargs': {\"bw\": 1}\n",
    "#     }\n",
    "# )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating a pair plot for selected parameters\n",
    "# az.plot_pair(data, divergences=False, var_names=['mu_1', 'mu_2'])\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gempy3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
